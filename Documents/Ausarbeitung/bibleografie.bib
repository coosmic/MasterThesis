@article{ThreeBasics,
    author = {Ziamtsov, Illia and Navlakha, Saket},
    title = "{Machine Learning Approaches to Improve Three Basic Plant Phenotyping Tasks Using Three-Dimensional Point Clouds1[OPEN]}",
    journal = {Plant Physiology},
    volume = {181},
    number = {4},
    pages = {1425-1440},
    year = {2019},
    month = {10},
    abstract = "{Developing automated methods to efficiently process large volumes of point cloud data remains a challenge for three-dimensional (3D) plant phenotyping applications. Here, we describe the development of machine learning methods to tackle three primary challenges in plant phenotyping: lamina/stem classification, lamina counting, and stem skeletonization. For classification, we assessed and validated the accuracy of our methods on a dataset of 54 3D shoot architectures, representing multiple growth conditions and developmental time points for two Solanaceous species, tomato (Solanum lycopersicum cv 75 m82D) and Nicotiana benthamiana. Using deep learning, we classified lamina versus stems with 97.8\\% accuracy. Critically, we also demonstrated the robustness of our method to growth conditions and species that have not been trained on, which is important in practical applications but is often untested. For lamina counting, we developed an enhanced region-growing algorithm to reduce oversegmentation; this method achieved 86.6\\% accuracy, outperforming prior methods developed for this problem. Finally, for stem skeletonization, we developed an enhanced tip detection technique, which ran an order of magnitude faster and generated more precise skeleton architectures than prior methods. Overall, our improvements enable higher throughput and accurate extraction of phenotypic properties from 3D point cloud data.}",
    issn = {0032-0889},
    doi = {10.1104/pp.19.00524},
    url = {https://doi.org/10.1104/pp.19.00524},
    eprint = {https://academic.oup.com/plphys/article-pdf/181/4/1425/36061573/plphys\_v181\_4\_1425.pdf},
}

@article{RegionGrowing,
  title={An Overlapping-Free Leaf Segmentation Method for Plant Point Clouds},
  author={Dawei Li and Yan Cao and Guoliang Shi and Xin Cai and Y. Chen and Sifan Wang and Siyuan Yan},
  journal={IEEE Access},
  year={2019},
  volume={7},
  pages={129054-129070}
}

@article{Sift3D,
  author = {HÃ¤nsch, Ronny and Weber, Thomas and Hellwich, Olaf},
  year = {2014},
  month = {09},
  pages = {},
  title = {Comparison of 3D Interest Point Detectors and Descriptors for Point Cloud Fusion},
  volume = {II-3},
  journal = {ISPRS Annals of Photogrammetry, Remote Sensing and Spatial Information Sciences},
  doi = {10.5194/isprsannals-II-3-57-2014}
}

@article{Sift,
  title={Distinctive image features from scale-invariant keypoints},
  author={Lowe, David G},
  journal={International journal of computer vision},
  volume={60},
  number={2},
  pages={91--110},
  year={2004},
  publisher={Springer}
}

https://www.tarjomefa.com/wp-content/uploads/2016/09/5349-English.pdf
@article{SURF,
  title={Speeded-up robust features (SURF)},
  author={Bay, Herbert and Ess, Andreas and Tuytelaars, Tinne and Van Gool, Luc},
  journal={Computer vision and image understanding},
  volume={110},
  number={3},
  pages={346--359},
  year={2008},
  publisher={Elsevier}
}

https://link.springer.com/content/pdf/10.1007/978-3-642-15561-1_56.pdf
@inproceedings{BRIEF,
  title={Brief: Binary robust independent elementary features},
  author={Calonder, Michael and Lepetit, Vincent and Strecha, Christoph and Fua, Pascal},
  booktitle={European conference on computer vision},
  pages={778--792},
  year={2010},
  organization={Springer}
}

http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.370.4395&rep=rep1&type=pdf
@inproceedings{ORB,
  title={ORB: An efficient alternative to SIFT or SURF},
  author={Rublee, Ethan and Rabaud, Vincent and Konolige, Kurt and Bradski, Gary},
  booktitle={2011 International conference on computer vision},
  pages={2564--2571},
  year={2011},
  organization={Ieee}
}

https://lcas.lincoln.ac.uk/wp/wp-content/uploads/2021/09/p1.08-TAROS2021paper19.pdf
@article{alouacheevaluation,
  title={Evaluation of an OpenCV Implementation of Structure from Motion on Open Source Data},
  author={Alouache, Ali and Wu, Qinghe}
}

@article{ICP,
  title={Fast and Robust Iterative Closest Point},
  author={Zhang, Juyong and Yao, Yuxin and Deng, Bailin},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2021},
  publisher={IEEE}
}

@misc{ODM,
    title={Open Drone Map - A command line toolkit to generate maps, point clouds, 3D models and DEMs from drone, balloon or kite images.},
    author={pierotofy},
    year={2020},
    url={https://github.com/OpenDroneMap/ODM}
}

@misc{schoenberger2016sfm,
    author={Sch\"{o}nberger, Johannes Lutz and Frahm, Jan-Michael},
    title={Structure-from-Motion Revisited},
    booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2016},
}

@inproceedings{schoenberger2016mvs,
    author={Sch\"{o}nberger, Johannes Lutz and Zheng, Enliang and Pollefeys, Marc and Frahm, Jan-Michael},
    title={{Pixelwise View Selection for Unstructured Multi-View Stereo}},
    booktitle={European Conference on Computer Vision (ECCV)},
    year={2016}
}


@misc{Moulon2012,
  doi = {10.1007/978-3-642-37447-0_20},
  year  = {2012},
  publisher = {Springer Berlin Heidelberg},
  pages = {257--270},
  author = {Pierre Moulon and Pascal Monasse and Renaud Marlet},
  title = {Adaptive Structure from Motion with a~Contrario Model Estimation},
  booktitle = {Proceedings of the Asian Computer Vision Conference (ACCV 2012)}
}

@inproceedings{qi2017pointnet,
  title={Pointnet: Deep learning on point sets for 3d classification and segmentation},
  author={Qi, Charles R and Su, Hao and Mo, Kaichun and Guibas, Leonidas J},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={652--660},
  year={2017}
}

@article{qi2017pointnet++,
  title={Pointnet++: Deep hierarchical feature learning on point sets in a metric space},
  author={Qi, Charles R and Yi, Li and Su, Hao and Guibas, Leonidas J},
  journal={arXiv preprint arXiv:1706.02413},
  year={2017}
}

@article{lidar,
  title={Review on Lidar Technology},
  author={Mehendale, Ninad and Neoge, Srushti},
  journal={ssrn preprint ssrn:3604309},
  year={2020},
  url={https://ssrn.com/abstract=3604309 }
}

@inproceedings{icp_org,
  title={Method for registration of 3-D shapes},
  author={Besl, Paul J and McKay, Neil D},
  booktitle={Sensor fusion IV: control paradigms and data structures},
  volume={1611},
  pages={586--606},
  year={1992},
  organization={International Society for Optics and Photonics}
}

@inproceedings{Ziner2005PointSR,
  title={Point Set Registration with Integrated Scale Estimation},
  author={T. Zin{\ss}er and J. Schmidt and H. Niemann},
  booktitle = {Point Set Registration with Integrated Scale Estimation},
  year={2005}
}

@InProceedings{Wang_2019_ICCV,
  title={Deep Closest Point: Learning Representations for Point Cloud Registration},
  author={Wang, Yue and Solomon, Justin M.},
  booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
  month = {October},
  year={2019}
}

@misc{aoki2019pointnetlk,
      title={PointNetLK: Robust and Efficient Point Cloud Registration using PointNet}, 
      author={Yasuhiro Aoki and Hunter Goforth and Rangaprasad Arun Srivatsan and Simon Lucey},
      year={2019},
      eprint={1903.05711},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{Yew_2020,
   title={RPM-Net: Robust Point Matching Using Learned Features},
   ISBN={9781728171685},
   url={http://dx.doi.org/10.1109/CVPR42600.2020.01184},
   DOI={10.1109/cvpr42600.2020.01184},
   journal={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
   publisher={IEEE},
   author={Yew, Zi Jian and Lee, Gim Hee},
   year={2020},
   month={Jun}
}

@misc{yuan2020deepgmr,
      title={DeepGMR: Learning Latent Gaussian Mixture Models for Registration}, 
      author={Wentao Yuan and Ben Eckart and Kihwan Kim and Varun Jampani and Dieter Fox and Jan Kautz},
      year={2020},
      eprint={2008.09088},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{wang2019prnet,
      title={PRNet: Self-Supervised Learning for Partial-to-Partial Registration}, 
      author={Yue Wang and Justin M. Solomon},
      year={2019},
      eprint={1910.12240},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{sarode2019pcrnet,
      title={PCRNet: Point Cloud Registration Network using PointNet Encoding}, 
      author={Vinit Sarode and Xueqian Li and Hunter Goforth and Yasuhiro Aoki and Rangaprasad Arun Srivatsan and Simon Lucey and Howie Choset},
      year={2019},
      eprint={1908.07906},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{rgbd_smartphones,
  author = {Akhil Taneja},
  title = {Top 10 Smartphones With A Dedicated Depth Sensor Camera To Capture Perfect Bokeh Shots},
  year = 2020,
  url = {https://www.cashify.in/top-10-smartphones-with-a-dedicated-depth-sensor-camera-to-capture-perfect-bokeh-shots},
  urldate = {2021-09-14}
}

@article{dgcnn,
  title={Dynamic Graph CNN for Learning on Point Clouds},
  author={Wang, Yue and Sun, Yongbin and Liu, Ziwei and Sarma, Sanjay E. and Bronstein, Michael M. and Solomon, Justin M.},
  journal={ACM Transactions on Graphics (TOG)},
  year={2019}
}

@misc{fan2016point,
      title={A Point Set Generation Network for 3D Object Reconstruction from a Single Image}, 
      author={Haoqiang Fan and Hao Su and Leonidas Guibas},
      year={2016},
      eprint={1612.00603},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{tatarchenko2017octree,
      title={Octree Generating Networks: Efficient Convolutional Architectures for High-resolution 3D Outputs}, 
      author={Maxim Tatarchenko and Alexey Dosovitskiy and Thomas Brox},
      year={2017},
      eprint={1703.09438},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{wang2018pixel2mesh,
      title={Pixel2Mesh: Generating 3D Mesh Models from Single RGB Images}, 
      author={Nanyang Wang and Yinda Zhang and Zhuwen Li and Yanwei Fu and Wei Liu and Yu-Gang Jiang},
      year={2018},
      eprint={1804.01654},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@Article{rs11222644,
AUTHOR = {Xia, Yan and Wang, Cheng and Xu, Yusheng and Zang, Yu and Liu, Weiquan and Li, Jonathan and Stilla, Uwe},
TITLE = {RealPoint3D: Generating 3D Point Clouds from a Single Image of Complex Scenarios},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {22},
ARTICLE-NUMBER = {2644},
URL = {https://www.mdpi.com/2072-4292/11/22/2644},
ISSN = {2072-4292},
ABSTRACT = {Generating 3D point clouds from a single image has attracted full attention from researchers in the field of multimedia, remote sensing and computer vision. With the recent proliferation of deep learning, various deep models have been proposed for the 3D point cloud generation. However, they require objects to be captured with absolutely clean backgrounds and fixed viewpoints, which highly limits their application in the real environment. To guide 3D point cloud generation, we propose a novel network, RealPoint3D, to integrate prior 3D shape knowledge into the network. Taking additional 3D information, RealPoint3D can handle 3D object generation from a single real image captured from any viewpoint and complex background. Specifically, provided a query image, we retrieve the nearest shape model from a pre-prepared 3D model database. Then, the image, together with the retrieved shape model, is fed into RealPoint3D to generate a fine-grained 3D point cloud. We evaluated the proposed RealPoint3D on the ShapeNet dataset and ObjectNet3D dataset for the 3D point cloud generation. Experimental results and comparisons with state-of-the-art methods demonstrate that our framework achieves superior performance. Furthermore, our proposed framework works well for real images in complex backgrounds (the image has the remaining objects in addition to the reconstructed object, and the reconstructed object may be occluded or truncated) with various viewing angles.},
DOI = {10.3390/rs11222644}
}

@inproceedings{RANSAC,
  title={Overview of the RANSAC Algorithm},
  author={K. Derpanis},
  year={2005},
  url={http://www.cse.yorku.ca/~kosta/CompVis_Notes/ransac.pdf}
}

@article{droughts,
author = {Masih, Ilyas and Maskey, Shreedhar and MussÃ¡, F and Trambauer, Patricia},
year = {2014},
month = {09},
pages = {3635-3649},
title = {A review of droughts on the African continent: A geospatial and long-term perspective},
volume = {18},
journal = {Hydrology and Earth System Sciences},
doi = {10.5194/hess-18-3635-2014}
}

@article{GoICP,
   title={Go-ICP: A Globally Optimal Solution to 3D ICP Point-Set Registration},
   volume={38},
   ISSN={2160-9292},
   url={http://dx.doi.org/10.1109/TPAMI.2015.2513405},
   DOI={10.1109/tpami.2015.2513405},
   number={11},
   journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Yang, Jiaolong and Li, Hongdong and Campbell, Dylan and Jia, Yunde},
   year={2016},
   month={Nov},
   pages={2241â2254}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  url={https://www.nature.com/articles/nature14539},
  publisher={Nature Publishing Group}
}

@article{ScaleLK,
	doi = {10.1088/1757-899x/768/7/072089},
	url = {https://doi.org/10.1088/1757-899x/768/7/072089},
	year = 2020,
	month = {mar},
	publisher = {{IOP} Publishing},
	volume = {768},
	pages = {072089},
	author = {Shuai Xu and Yanlei Shang},
	title = {{ScaleLK}: Registration of Point Clouds with Different Scales Using Deep Learning Methods},
	journal = {{IOP} Conference Series: Materials Science and Engineering},
  url={https://iopscience.iop.org/article/10.1088/1757-899X/768/7/072089/pdf},
	abstract = {3D point clouds are widely used in numerous research and applications, such as autonomous driving, industrial robots, and augmented reality, to represent the spatial structure of objects. The 3D point cloud registration aims to transform the source point cloud into the same coordinate system with the template point cloud, which is of great significance for the 3D reconstruction of the real world objects. ICP [1] is one of the most classic point cloud registration algorithms but it still has problems with efficiency and initialization. With the help of deep learning, PointNetLK [7] becomes a state-of-the-art point cloud registration method. Although PointNetLK is efficient and robust to some extent, it is not able to register point clouds with different scales. In this paper, we propose ScaleLK, an approach for registration of point clouds with different scales using deep learning methods. We have trained a feature extractor which supports scale feature and used this feature for registration of point clouds with different scales. We describe the architecture and compare its performance with other methods.}
}

@article{sears2007blob,
  title={To blob or not to blob: Large object storage in a database or a filesystem?},
  author={Sears, Russell and Van Ingen, Catharine and Gray, Jim},
  journal={arXiv preprint cs/0701168},
  year={2007},
  url={https://arxiv.org/pdf/cs/0701168.pdf}
}


